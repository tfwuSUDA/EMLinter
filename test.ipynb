{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config():\n",
    "    def __init__(self):\n",
    "        self.vocab_size=65\n",
    "        self.strvocab_size=3\n",
    "        self.embedding_size=100\n",
    "        self.strembedding_size=2\n",
    "        self.feature_size=64\n",
    "#         self.mi_kernel_size=[[1],[1,3],[1,3,5],[1,3,5,7]]\n",
    "#         self.lnc_kernel_size=[[1],[1,3,5],[1,3,5,9],[1,3,5,9,15]]\n",
    "#         self.mi_kernel_size=[2,4,6]\n",
    "#         self.lnc_kernel_size=[4,8,16]\n",
    "        self.mi_kernel_size=[1,3,5]\n",
    "        self.lnc_kernel_size=[3,7,11]\n",
    "        self.max_mi=25\n",
    "        self.max_lnc=22743\n",
    "        self.num_class=2\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from models import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import *\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm \n",
    "from torch.utils.data import DataLoader,Dataset,ConcatDataset\n",
    "\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"type args\")\n",
    "parser.add_argument('-batch_size', type=int, default=64, help=\"BatchSize\")\n",
    "parser.add_argument('-epochs', type=int, default=100, help=\"Epoch Num\")\n",
    "parser.add_argument('-train', type=str, default='True', help=\"Train or Eval\")\n",
    "parser.add_argument('-cuda_id', type=int, default='0', help=\"CUDA Num\")\n",
    "parser.add_argument('-model_save_path', type=str,\n",
    "                    default='./model', help=\"model save path\")\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self,txtpath):\n",
    "        if args.cuda_id != -1:\n",
    "            device = 'cuda:{}'.format(args.cuda_id)\n",
    "        else:\n",
    "            device = 'cpu'\n",
    "\n",
    "        self.data = txtpath\n",
    "        \n",
    "        self.featurelnc=pd.read_csv('../extracted_feature/lncfeature.csv',index_col=0)\n",
    "        self.featuremi=pd.read_csv('../extracted_feature/mifeature.csv',index_col=0)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        lncid=torch.from_numpy(self.data[index,0]).cuda(device)\n",
    "        miid=torch.from_numpy(self.data[index,1]).cuda(device)\n",
    "        strlncid=torch.from_numpy(self.featurelnc.iloc[index].to_numpy()).cuda(device)\n",
    "        strmiid=torch.from_numpy(self.featuremi.iloc[index].to_numpy()).cuda(device)\n",
    "        label=self.data[index,4]\n",
    "        return lncid,miid,strlncid.float(),strmiid.float(),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=np.load('../Data/id_trainval_seqstr.npy',allow_pickle=True)\n",
    "dataset = Data(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "test_ids=np.load('0_testset.npy')\n",
    "test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "testloader = torch.utils.data.DataLoader(dataset,batch_size=1, sampler=test_subsampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACC(testloader,model1,model2,model3):\n",
    "    softmax_0 = nn.Softmax(dim=1)\n",
    "    correct1, total1 = 0, 0\n",
    "    correct2, total2 = 0, 0\n",
    "    correct3, total3 = 0, 0\n",
    "    l=[]\n",
    "    p1=[]\n",
    "    s1=[]\n",
    "   \n",
    "    p2=[]\n",
    "    s2=[]\n",
    "\n",
    "    p3=[]\n",
    "    s3=[]\n",
    "    seq=[]\n",
    "    with torch.no_grad():\n",
    "      # Iterate over the test data and generate predictions\n",
    "        for i, data in tqdm(enumerate(testloader, 0)):\n",
    "\n",
    "            # Get inputs\n",
    "            lncsams,misams,strlncsams,strmisams,labels = data\n",
    "            seq.append(lncsams.detach().cpu())\n",
    "            labels=labels.long()\n",
    "            l.append([labels.detach().cpu()])\n",
    "            # Generate outputs\n",
    "            outputs1 = model1(misams,lncsams,strmisams,strlncsams)\n",
    "            # Set total and correct\n",
    "            _, predicted1 = torch.max(outputs1.data, 1)\n",
    "            total1 += labels.size(0)\n",
    "            correct1 += (predicted1 == labels.cuda(device)).sum().item()\n",
    "            p1.append(predicted1.detach().cpu())\n",
    "            s1.append([softmax_0(outputs1)[0][1].detach().cpu()])\n",
    "            \n",
    "            outputs2 = model2(misams,lncsams,strmisams,strlncsams)\n",
    "            # Set total and correct\n",
    "            _, predicted2 = torch.max(outputs2.data, 1)\n",
    "            total2+= labels.size(0)\n",
    "            correct2 += (predicted2 == labels.cuda(device)).sum().item()\n",
    "            p2.append(predicted2.detach().cpu())\n",
    "            s2.append([softmax_0(outputs2)[0][1].detach().cpu()])\n",
    "            \n",
    "            outputs3 = model3(misams,lncsams,strmisams,strlncsams)\n",
    "            # Set total and correct\n",
    "            _, predicted3 = torch.max(outputs3.data, 1)\n",
    "            total3 += labels.size(0)\n",
    "            correct3 += (predicted3 == labels.cuda(device)).sum().item()\n",
    "            p3.append(predicted3.detach().cpu())\n",
    "            s3.append([softmax_0(outputs3)[0][1].detach().cpu()])\n",
    "            \n",
    "            \n",
    "    return (100.0 * correct1 / total1),(100.0 * correct2 / total2),(100.0 * correct3 / total3),l,seq,p1,s1,p2,s2,p3,s3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4968it [07:33, 10.94it/s]\n"
     ]
    }
   ],
   "source": [
    "if args.cuda_id != -1:\n",
    "    device = 'cuda:{}'.format(args.cuda_id)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "cf=config()\n",
    "model1=AttentionMiRNATAR_v2(cf)\n",
    "model1.load_state_dict(torch.load(\"./Results/fold1/model-epoch-90_v2.pth\"))\n",
    "model1.to(device)\n",
    "model1.eval()\n",
    "model2=AttentionMiRNATAR_v3(cf)\n",
    "model2.load_state_dict(torch.load(\"./Results/fold1/model-epoch-90_v3.pth\"))\n",
    "model2.to(device)\n",
    "model2.eval()\n",
    "model3=AttentionMiRNATAR_v7(cf)\n",
    "model3.load_state_dict(torch.load(\"./Results/fold1/model-epoch-90_v7.pth\"))\n",
    "model3.to(device)\n",
    "model3.eval()\n",
    "\n",
    "res1,res2,res3,l,seq,p1,s1,p2,s2,p3,s3=ACC(testloader,model1,model2,model3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.05636070853463 90.09661835748793 86.47342995169082\n"
     ]
    }
   ],
   "source": [
    "print(res1,res2,res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256/2195162950.py:16: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  l=np.array(l).astype('float')\n",
      "/tmp/ipykernel_256/2195162950.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  l=np.array(l).astype('float')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78787875\n",
      "2393 101 291 2183\n",
      "F1-Score:0.9176\n",
      "AUC:0.9678\n",
      "ACC:0.9211\n",
      "Sn:0.8824\n",
      "Sp:0.9595\n",
      "Pre:0.9558\n",
      "Mcc:0.8446\n",
      "PRC:0.9733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,roc_auc_score,f1_score,average_precision_score,roc_curve\n",
    "\n",
    "# from collections import Counter\n",
    "# for i in seq1[:10]:\n",
    "#     c=0\n",
    "#     for j in i[0]:\n",
    "#         if j==0:\n",
    "#             c+=1\n",
    "#     print(22743-c)\n",
    "\n",
    "\n",
    "w1=0.6\n",
    "w2=0.2\n",
    "w3=0.2\n",
    "\n",
    "l=np.array(l).astype('float')\n",
    "s=[s1[i][0]*w1+s2[i][0]*w2+s3[i][0]*w3 for i in range(len(s1))]\n",
    "# s=[s1[i][0]*0.85+s2[i][0]*0.15 for i in range(len(s1))]\n",
    "\n",
    "\n",
    "s1=np.array(s1).astype('float')\n",
    "s2=np.array(s2).astype('float')\n",
    "s3=np.array(s3).astype('float')\n",
    "\n",
    "p_new=[]\n",
    "\n",
    "FPR, recall, thresholds1 = roc_curve(l,s, pos_label=1)\n",
    "gmean=np.sqrt(recall*(1-FPR))\n",
    "index=np.argmax(gmean)\n",
    "th1=thresholds1[index]\n",
    "print(th1)\n",
    "\n",
    "# FPR, recall, thresholds2 = roc_curve(l,s2, pos_label=1)\n",
    "# gmean=np.sqrt(recall*(1-FPR))\n",
    "# index=np.argmax(gmean)\n",
    "# th2=thresholds2[index]\n",
    "\n",
    "# FPR, recall, thresholds3 = roc_curve(l,s3, pos_label=1)\n",
    "# gmean=np.sqrt(recall*(1-FPR))\n",
    "# index=np.argmax(gmean)\n",
    "# th3=thresholds3[index]\n",
    "\n",
    "# print(th1,th2,th3)\n",
    "\n",
    "# for i in range(len(s1)):\n",
    "#     if s1[i]<th1:\n",
    "#         c1=0\n",
    "#     else:\n",
    "#         c1=1\n",
    "#     if s2[i]<th2:\n",
    "#         c2=0\n",
    "#     else:\n",
    "#         c2=1\n",
    "#     if s3[i]<th3:\n",
    "#         c3=0\n",
    "#     else:\n",
    "#         c3=1\n",
    "\n",
    "#     if c1+c2+c3>1:\n",
    "#         p_new.append(1)\n",
    "#     else:\n",
    "#         p_new.append(0)\n",
    "\n",
    "for i in s:\n",
    "    if i<th1:\n",
    "        p_new.append(0)\n",
    "    else:\n",
    "        p_new.append(1)\n",
    "# s=s3\n",
    "\n",
    "p=p_new\n",
    "\n",
    "tn,fp,fn,tp = confusion_matrix(l, p).ravel() \n",
    "print(tn,fp,fn,tp)\n",
    "pp = tp+fn\n",
    "pn = tn+fp\n",
    "sensitivity = tp / pp\n",
    "specificity = tn / pn\n",
    "precision = tp / (tp + fp)\n",
    "acc = (tp+tn) / (pp+pn)\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print(\"F1-Score:{:.4f}\".format(f1_score(l,p)))\n",
    "print(\"AUC:{:.4f}\".format(roc_auc_score(l,s)))\n",
    "print(\"ACC:{:.4f}\".format(acc))\n",
    "print(\"Sn:{:.4f}\".format(sensitivity))\n",
    "print(\"Sp:{:.4f}\".format(specificity))\n",
    "print(\"Pre:{:.4f}\".format(precision))\n",
    "print(\"Mcc:{:.4f}\".format(mcc))\n",
    "print(\"PRC:{:.4f}\".format(average_precision_score(l,s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold4:\n",
    "F1-Score:0.9242\n",
    "AUC:0.9694\n",
    "ACC:0.9261\n",
    "Sn:0.8977\n",
    "Sp:0.9548\n",
    "Pre:0.9523\n",
    "Mcc:0.8537\n",
    "PRC:0.9725\n",
    "    \n",
    "fold2:   \n",
    "0.7706207\n",
    "2361 127 263 2217\n",
    "F1-Score:0.9192\n",
    "AUC:0.9694\n",
    "ACC:0.9215\n",
    "Sn:0.8940\n",
    "Sp:0.9490\n",
    "Pre:0.9458\n",
    "Mcc:0.8442\n",
    "PRC:0.9732\n",
    "\n",
    "fold3\n",
    "F1-Score:0.9136\n",
    "AUC:0.9632\n",
    "ACC:0.9147\n",
    "Sn:0.8965\n",
    "Sp:0.9331\n",
    "Pre:0.9315\n",
    "Mcc:0.8299\n",
    "PRC:0.9674\n",
    "\n",
    "fold5\n",
    "F1-Score:0.9101\n",
    "AUC:0.9656\n",
    "ACC:0.9128\n",
    "Sn:0.8867\n",
    "Sp:0.9387\n",
    "Pre:0.9348\n",
    "Mcc:0.8267\n",
    "PRC:0.9693\n",
    "\n",
    "fold1\n",
    "0.7949260383844375\n",
    "2372 122 289 2185\n",
    "F1-Score:0.9140\n",
    "AUC:0.9656\n",
    "ACC:0.9173\n",
    "Sn:0.8832\n",
    "Sp:0.9511\n",
    "Pre:0.9471\n",
    "Mcc:0.8364\n",
    "PRC:0.9715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4968it [00:40, 123.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.87520128824477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
